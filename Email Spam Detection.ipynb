{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18190599-7ea4-4c48-86d5-d9d0f56b75fe",
   "metadata": {},
   "source": [
    "### Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d9f496-63ef-41fb-8939-064f7bbef272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef8029f-d2dd-4585-9a56-6471f3004f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv('spam_ham_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba85e11-8d2b-436c-b541-629db0014e91",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0aa6a23-9c31-4f54-98dd-0e2a6d5eef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Custom Stopwords List \n",
    "\n",
    "# This list is used for removing common words from the text.\n",
    "\n",
    "stop_words = set([\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\",\n",
    "    'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers',\n",
    "    'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n",
    "    'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
    "    'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but',\n",
    "    'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against',\n",
    "    'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "    'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when',\n",
    "    'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no',\n",
    "    'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don',\n",
    "    \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n",
    "    \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\",\n",
    "    'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn',\n",
    "    \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150f6536-61a5-4eaa-8525-4b2ab1717588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Text Preprocessing Function ---\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = ''.join([char.lower() for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply the preprocessing function to the 'text' column\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a2c8f1-45e4-42ee-a776-f629e87512ea",
   "metadata": {},
   "source": [
    "### Feature Extraction and Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03565894-d3c3-45ab-9e49-074cf3094d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TF-IDF Vectorization \n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2983887-6e02-4bcb-8ac1-96cc486261d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the preprocessed text data\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(df['cleaned_text'])\n",
    "y = df['label_num'] # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99c465ac-ad59-4711-a0ea-021bd2cba67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split the data into training and testing sets \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1be0b9-34e5-4e81-8734-aa119b468fb3",
   "metadata": {},
   "source": [
    "###  Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "508908ac-88d3-4776-a042-ef61badad989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Naive Bayes Model ---\n",
      "Naive Bayes Accuracy: 0.9516908212560387\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       742\n",
      "           1       0.90      0.93      0.92       293\n",
      "\n",
      "    accuracy                           0.95      1035\n",
      "   macro avg       0.94      0.94      0.94      1035\n",
      "weighted avg       0.95      0.95      0.95      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Naive Bayes Model \n",
    "\n",
    "print(\"--- Training Naive Bayes Model ---\")\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "nb_predictions = naive_bayes_model.predict(X_test)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b719d98-151b-4e3c-a34f-ff325c57f4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training SVM Model ---\n",
      "SVM Accuracy: 0.9884057971014493\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       742\n",
      "           1       0.98      0.98      0.98       293\n",
      "\n",
      "    accuracy                           0.99      1035\n",
      "   macro avg       0.99      0.98      0.99      1035\n",
      "weighted avg       0.99      0.99      0.99      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  SVM Model \n",
    "\n",
    "print(\"\\n--- Training SVM Model ---\")\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2edaad0b-2b87-4c0c-88f0-1c5d152e97c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model and TF-IDF vectorizer have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#  'svm_model' is my trained SVM classifier\n",
    "# and 'tfidf_vectorizer' is my fitted TfidfVectorizer.\n",
    "\n",
    "# Save the trained SVM model to a file\n",
    "joblib.dump(svm_model, 'svm_model.joblib')\n",
    "\n",
    "# Save the fitted TF-IDF vectorizer to a file\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "\n",
    "print(\"SVM model and TF-IDF vectorizer have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d8aa11-5535-40af-820e-d297cc33fa66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
